{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=skyblue>A simple example of Principal Component Analysis</font>\n",
    "\n",
    "Data is not standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=yellow>Use numpy</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "[[1 2 3 4 5]\n",
      " [2 1 4 5 4]]\n",
      "Scov:\n",
      "[[2.5 2. ]\n",
      " [2.  2.7]]\n",
      "eigenvalues:\n",
      "[4.60249844 0.59750156]\n",
      "(sigma_x1, sigma_x2) = (2.5, 2.7), 與 eigenvalues: [4.60249844 0.59750156] 相加相等\n",
      "eigenvectors:\n",
      "[[-0.68922507 -0.72454731]\n",
      " [-0.72454731  0.68922507]]\n",
      "v1:\n",
      "[0.68922507 0.72454731]\n",
      "v2:\n",
      "[-0.72454731  0.68922507]\n",
      "Z:\n",
      "[[ 2.13831969  2.10299744  4.96586445  6.37963683  6.34431458]\n",
      " [ 0.65390282 -0.75986956  0.58325833  0.54793608 -0.8658363 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = np.array([[1, 2, 3, 4, 5], [2, 1, 4, 5, 4]])\n",
    "print(\"X:\\n{}\".format(X))\n",
    "# np.cov 接受 行=變數，列=樣本\n",
    "Scov = np.cov(X) # compute covariance matrix\n",
    "print(\"Scov:\\n{}\".format(Scov))\n",
    "# compute eigenvectors and eigenvalues\n",
    "eigenvalues, eigenvectors = np.linalg.eig(Scov)\n",
    "# sort eigenvalues and eigenvectors\n",
    "idx = eigenvalues.argsort()[::-1]\n",
    "eigenvalues = eigenvalues[idx]\n",
    "eigenvectors = eigenvectors[:, idx] # eigenvectors are column-wise\n",
    "\n",
    "print(\"eigenvalues:\\n{}\".format(eigenvalues))\n",
    "print(f\"(sigma_x1, sigma_x2) = ({Scov[0, 0]}, {Scov[1, 1]}), 與 eigenvalues: {eigenvalues} 相加相等\")\n",
    "print(\"eigenvectors:\\n{}\".format(eigenvectors))\n",
    "v1 = -eigenvectors[:, 0] # reverse the direction of the first eigenvector\n",
    "v2 = eigenvectors[:, 1] # keep the direction of the second eigenvector\n",
    "print(\"v1:\\n{}\".format(v1))\n",
    "print(\"v2:\\n{}\".format(v2))\n",
    "\n",
    "# transform data by v1 and v2\n",
    "Z1 = np.dot(v1, X)  # project X onto v1，矩陣相乘\n",
    "Z2 = np.dot(v2, X)\n",
    "Z = np.vstack((Z1, Z2))\n",
    "print(\"Z:\\n{}\".format(Z))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=yellow>Use sklearn PCA</font> \n",
    "\n",
    "注意：PCA.fit_transform 轉成新的座標軸前，會先將 X 置中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z:\n",
      "[[-2.24790691 -0.62202455]\n",
      " [-2.28322915  0.79174783]\n",
      " [ 0.57963785 -0.55138005]\n",
      " [ 1.99341023 -0.51605781]\n",
      " [ 1.95808798  0.89771457]]\n",
      "explained_variance:\n",
      "[4.60249844 0.59750156]\n",
      "explained_variance_ratio:\n",
      "[0.88509585 0.11490415]\n",
      "components:\n",
      "[[ 0.68922507  0.72454731]\n",
      " [ 0.72454731 -0.68922507]]\n",
      "v1:\n",
      "[0.68922507 0.72454731]\n",
      "v2:\n",
      "[ 0.72454731 -0.68922507]\n",
      "Z:\n",
      "[[-2.24790691 -2.28322915  0.57963785  1.99341023  1.95808798]\n",
      " [-0.62202455  0.79174783 -0.55138005 -0.51605781  0.89771457]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "Z = pca.fit_transform(X.T)\n",
    "print(\"Z:\\n{}\".format(Z))\n",
    "print(\"explained_variance:\\n{}\".format(pca.explained_variance_))\n",
    "print(\"explained_variance_ratio:\\n{}\".format(pca.explained_variance_ratio_))\n",
    "print(\"components:\\n{}\".format(pca.components_))\n",
    "\n",
    "# 自行計算 Z 值（以便控制 eigenvector 的方向）\n",
    "# print the first principal component\n",
    "v1 = pca.components_[0]\n",
    "print(\"v1:\\n{}\".format(v1))\n",
    "# print the second principal component\n",
    "v2 = pca.components_[1]\n",
    "print(\"v2:\\n{}\".format(v2))\n",
    "\n",
    "# Manually center the data\n",
    "X = X - np.mean(X, axis=1, keepdims=True)\n",
    "# transform data by v1 and v2\n",
    "Z1 = np.dot(v1, X)\n",
    "Z2 = np.dot(v2, X)\n",
    "Z = np.vstack((Z1, Z2))\n",
    "print(\"Z:\\n{}\".format(Z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=yellow>Use standardized data and Draw Scatter Plot for X and Z</font>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ShallowML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
